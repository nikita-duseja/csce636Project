{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "import os\n",
    "\n",
    "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>forces</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565  Sentence: 47958     impact   NN      O\n",
       "1048566  Sentence: 47958          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568  Sentence: 47959     forces  NNS      O\n",
       "1048569  Sentence: 47959       said  VBD      O\n",
       "1048570  Sentence: 47959       they  PRP      O\n",
       "1048571  Sentence: 47959  responded  VBD      O\n",
       "1048572  Sentence: 47959         to   TO      O\n",
       "1048573  Sentence: 47959        the   DT      O\n",
       "1048574  Sentence: 47959     attack   NN      O"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35179"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "words.sort()\n",
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "        \n",
    "# class NERModel(object):\n",
    "#     def __init__(self,data):\n",
    "#         self.sentenceGetter = SentenceGetter(data)\n",
    "#         self.model = modelSpec()\n",
    "        \n",
    "#     def modelSpec():\n",
    "#         input = Input(shape=(max_len,))\n",
    "#         model = Embedding(input_dim=n_words + 1, output_dim=20,input_length=max_len, mask_zero=True)(input)\n",
    "#         model = Bidirectional(LSTM(units=50, return_sequences=True,recurrent_dropout=0.1))(model)\n",
    "#         model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  \n",
    "#         crf = CRF(n_tags)\n",
    "#         out = crf(model)\n",
    "#         model = Model(input, out)\n",
    "#         model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "#         return model\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "tags.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "getter = SentenceGetter(data)\n",
    "sent = getter.get_next()\n",
    "print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 75\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11522"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx[\"Obama\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx[\"B-geo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words + 1, output_dim=50,\n",
    "                  input_length=max_len, mask_zero=True)(input)  # 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags)  # CRF layer\n",
    "out = crf(model)  # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jharsh/miniconda3/envs/kerasGPU1/lib/python3.6/site-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "/home/jharsh/miniconda3/envs/kerasGPU1/lib/python3.6/site-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38846 samples, validate on 4317 samples\n",
      "Epoch 1/20\n",
      "38846/38846 [==============================] - 194s 5ms/step - loss: 0.0928 - crf_viterbi_accuracy: 0.9753 - val_loss: 0.0344 - val_crf_viterbi_accuracy: 0.9883\n",
      "Epoch 2/20\n",
      "38846/38846 [==============================] - 191s 5ms/step - loss: 0.0273 - crf_viterbi_accuracy: 0.9899 - val_loss: 0.0264 - val_crf_viterbi_accuracy: 0.9893\n",
      "Epoch 3/20\n",
      "38846/38846 [==============================] - 191s 5ms/step - loss: 0.0210 - crf_viterbi_accuracy: 0.9915 - val_loss: 0.0228 - val_crf_viterbi_accuracy: 0.9905\n",
      "Epoch 4/20\n",
      "38846/38846 [==============================] - 191s 5ms/step - loss: 0.0185 - crf_viterbi_accuracy: 0.9923 - val_loss: 0.0221 - val_crf_viterbi_accuracy: 0.9905\n",
      "Epoch 5/20\n",
      "38846/38846 [==============================] - 191s 5ms/step - loss: 0.0168 - crf_viterbi_accuracy: 0.9928 - val_loss: 0.0220 - val_crf_viterbi_accuracy: 0.9909\n",
      "Epoch 6/20\n",
      "38846/38846 [==============================] - 191s 5ms/step - loss: 0.0158 - crf_viterbi_accuracy: 0.9932 - val_loss: 0.0220 - val_crf_viterbi_accuracy: 0.9903\n",
      "Epoch 7/20\n",
      "38846/38846 [==============================] - 191s 5ms/step - loss: 0.0149 - crf_viterbi_accuracy: 0.9935 - val_loss: 0.0220 - val_crf_viterbi_accuracy: 0.9906\n",
      "Epoch 8/20\n",
      "38846/38846 [==============================] - 191s 5ms/step - loss: 0.0142 - crf_viterbi_accuracy: 0.9939 - val_loss: 0.0217 - val_crf_viterbi_accuracy: 0.9907\n",
      "Epoch 9/20\n",
      "38846/38846 [==============================] - 191s 5ms/step - loss: 0.0134 - crf_viterbi_accuracy: 0.9942 - val_loss: 0.0226 - val_crf_viterbi_accuracy: 0.9902\n",
      "Epoch 10/20\n",
      "38846/38846 [==============================] - 191s 5ms/step - loss: 0.0127 - crf_viterbi_accuracy: 0.9944 - val_loss: 0.0229 - val_crf_viterbi_accuracy: 0.9905\n",
      "Epoch 11/20\n",
      "38846/38846 [==============================] - 209s 5ms/step - loss: 0.0120 - crf_viterbi_accuracy: 0.9948 - val_loss: 0.0243 - val_crf_viterbi_accuracy: 0.9900\n",
      "Epoch 12/20\n",
      "38846/38846 [==============================] - 222s 6ms/step - loss: 0.0113 - crf_viterbi_accuracy: 0.9950 - val_loss: 0.0250 - val_crf_viterbi_accuracy: 0.9897\n",
      "Epoch 13/20\n",
      "38846/38846 [==============================] - 221s 6ms/step - loss: 0.0107 - crf_viterbi_accuracy: 0.9953 - val_loss: 0.0251 - val_crf_viterbi_accuracy: 0.9900\n",
      "Epoch 14/20\n",
      "38846/38846 [==============================] - 221s 6ms/step - loss: 0.0100 - crf_viterbi_accuracy: 0.9956 - val_loss: 0.0256 - val_crf_viterbi_accuracy: 0.9898\n",
      "Epoch 15/20\n",
      "38846/38846 [==============================] - 221s 6ms/step - loss: 0.0094 - crf_viterbi_accuracy: 0.9959 - val_loss: 0.0280 - val_crf_viterbi_accuracy: 0.9895\n",
      "Epoch 16/20\n",
      "38846/38846 [==============================] - 222s 6ms/step - loss: 0.0088 - crf_viterbi_accuracy: 0.9962 - val_loss: 0.0282 - val_crf_viterbi_accuracy: 0.9893\n",
      "Epoch 17/20\n",
      "38846/38846 [==============================] - 230s 6ms/step - loss: 0.0082 - crf_viterbi_accuracy: 0.9964 - val_loss: 0.0301 - val_crf_viterbi_accuracy: 0.9887\n",
      "Epoch 18/20\n",
      "38846/38846 [==============================] - 221s 6ms/step - loss: 0.0077 - crf_viterbi_accuracy: 0.9967 - val_loss: 0.0305 - val_crf_viterbi_accuracy: 0.9886\n",
      "Epoch 19/20\n",
      "38846/38846 [==============================] - 221s 6ms/step - loss: 0.0073 - crf_viterbi_accuracy: 0.9969 - val_loss: 0.0323 - val_crf_viterbi_accuracy: 0.9883\n",
      "Epoch 20/20\n",
      "38846/38846 [==============================] - 221s 6ms/step - loss: 0.0068 - crf_viterbi_accuracy: 0.9970 - val_loss: 0.0346 - val_crf_viterbi_accuracy: 0.9883\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=20, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('BiLSTM_CRF_NER.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4796/4796 [==============================] - 9s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "test_pred = model.predict(X_te, verbose=1)\n",
    "\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        org       0.62      0.68      0.65      2113\n",
      "        per       0.76      0.72      0.74      1738\n",
      "        geo       0.82      0.86      0.84      3928\n",
      "        gpe       0.94      0.93      0.94      1561\n",
      "        tim       0.84      0.85      0.85      1972\n",
      "        art       0.06      0.17      0.09        35\n",
      "        eve       0.22      0.32      0.26        25\n",
      "        nat       0.43      0.45      0.44        20\n",
      "\n",
      "avg / total       0.79      0.81      0.80     11392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_te)):\n",
    "    p = model.predict(np.array([X_te[i]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    true = np.argmax(y_te[i], -1)\n",
    "    fileName = \"testFile\"+str(i)\n",
    "    file = open(fileName,'w')\n",
    "    \n",
    "    file.write(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "    file.write(30 * \"=\")\n",
    "    for w, t, pred in zip(X_te[i], true, p[0]):\n",
    "        if w != 0:\n",
    "            file.write(\"{:15}: {:5} {}\".format(words[w-1], tags[t], tags[pred]))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
