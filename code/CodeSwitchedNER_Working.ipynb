{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2TagDict = {}\n",
    "dictTags = {}\n",
    "data = []\n",
    "\n",
    "with open('data.tsv', 'r') as train_data:\n",
    "    tagLine = train_data.readline()\n",
    "    while tagLine:\n",
    "        tokens = tagLine.split()\n",
    "        if len(tokens) == 6:\n",
    "            if tokens[0] in dictTags:\n",
    "                dictTags[tokens[0]][tokens[4]] = tokens[5]\n",
    "            else:\n",
    "                dictTags[tokens[0]] = {}\n",
    "                dictTags[tokens[0]][tokens[4]] = tokens[5]\n",
    "\n",
    "            word2TagDict[tokens[4]] = tokens[5]\n",
    "        tagLine = train_data.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36910"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for tweet in dictTags:\n",
    "    sentence = dictTags[tweet]\n",
    "    listTup = [(k, v) for k, v in sentence.items()]\n",
    "    data.append(listTup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36910"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('So', 'O'), ('happy', 'O'), ('I', 'O'), ('get', 'O'), ('to', 'O'), ('go', 'O'), ('home', 'O'), ('in', 'O'), ('two', 'O'), ('days', 'O'), ('‚òÄÔ∏èüå¥', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So happy I get to go home in two days ‚òÄÔ∏èüå¥'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = ' '.join(token[0] for token in data[0])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So happy I get to go home in two days [sune[palm_treee\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize(res, '[emoji]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(word2TagDict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62515"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(word2TagDict.keys()))\n",
    "tags = list(set(word2TagDict.values()))\n",
    "words.sort()\n",
    "tags.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-EVENT',\n",
       " 'B-GROUP',\n",
       " 'B-LOC',\n",
       " 'B-ORG',\n",
       " 'B-OTHER',\n",
       " 'B-PER',\n",
       " 'B-PROD',\n",
       " 'B-TIME',\n",
       " 'B-TITLE',\n",
       " 'I-EVENT',\n",
       " 'I-GROUP',\n",
       " 'I-LOC',\n",
       " 'I-ORG',\n",
       " 'I-OTHER',\n",
       " 'I-PER',\n",
       " 'I-PROD',\n",
       " 'I-TIME',\n",
       " 'I-TITLE',\n",
       " 'O']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 75\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=num_words-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[1]] for w in s] for s in data]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=num_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='best_cs_ner_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=num_words, output_dim=50, input_length=max_len)(input)\n",
    "model = Dropout(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(num_tags, activation=\"softmax\"))(model)  # softmax output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29897 samples, validate on 3322 samples\n",
      "Epoch 1/15\n",
      "29897/29897 [==============================] - 203s 7ms/step - loss: 0.0449 - acc: 0.9949 - val_loss: 0.0217 - val_acc: 0.9953\n",
      "Epoch 2/15\n",
      "29897/29897 [==============================] - 201s 7ms/step - loss: 0.0159 - acc: 0.9962 - val_loss: 0.0193 - val_acc: 0.9958\n",
      "Epoch 3/15\n",
      "29897/29897 [==============================] - 201s 7ms/step - loss: 0.0113 - acc: 0.9972 - val_loss: 0.0185 - val_acc: 0.9961\n",
      "Epoch 4/15\n",
      "29897/29897 [==============================] - 203s 7ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0190 - val_acc: 0.9962\n",
      "Epoch 5/15\n",
      "29897/29897 [==============================] - 261s 9ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0198 - val_acc: 0.9961\n",
      "Epoch 6/15\n",
      "29897/29897 [==============================] - 266s 9ms/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0204 - val_acc: 0.9963\n",
      "Epoch 7/15\n",
      "29897/29897 [==============================] - 223s 7ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0218 - val_acc: 0.9959\n",
      "Epoch 8/15\n",
      "29897/29897 [==============================] - 299s 10ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0223 - val_acc: 0.9960\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=16, epochs=15, callbacks=callbacks, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('best_cs_ner_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3691/3691 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "test_pred = model.predict(X_te, verbose=1)\n",
    "\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        PER       0.45      0.46      0.45       342\n",
      "        LOC       0.45      0.48      0.46       181\n",
      "       PROD       0.73      0.17      0.27        96\n",
      "      TITLE       0.00      0.00      0.00        68\n",
      "      GROUP       0.00      0.00      0.00        65\n",
      "       TIME       0.00      0.00      0.00        47\n",
      "        ORG       0.00      0.00      0.00        65\n",
      "      OTHER       0.00      0.00      0.00        33\n",
      "      EVENT       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.33      0.29      0.29       912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
